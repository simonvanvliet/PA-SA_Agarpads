{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process segmentation made with Ilastik"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the identical steps as in notebook 1A, but in a more streamlined way, allowing for batch processing without visual inspection.\n",
    "\n",
    "The processing functions have been moved to the process_colonies.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#next two lines make sure that Matplotlib plots are shown properly in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#main data analysis packages\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "\n",
    "#path handling\n",
    "import pathlib\n",
    "import h5py\n",
    "\n",
    "#dask cash\n",
    "from dask.cache import Cache\n",
    "cache = Cache(4e9)  # Leverage 4 gigabytes of memory\n",
    "cache.register()    # Turn cache on globally\n",
    "\n",
    "import process_colonies as pc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to registered file\n",
    "path_reg_im = pathlib.Path(\"/Volumes/ScientificData/Users/Giulia(botgiu00)/Collaborations/Ashley/2023-04-11-agar-pad-processed/\")\n",
    "\n",
    "#set path to Ilastik output file\n",
    "path_seg_im = pathlib.Path(\"/Volumes/ScientificData/Users/Giulia(botgiu00)/Collaborations/Ashley/2023-04-11-agar-pad-processed/Probabilities_8bit_export/\")\n",
    "\n",
    "#set path to output csv files\n",
    "path_data_files = pathlib.Path() \n",
    "\n",
    "#set filenames\n",
    "exp_name = \"20230411\"\n",
    "\n",
    "#set to true to calculate distance between colony edges, more accurate that center to center distance, but very slow\n",
    "calc_edge_dist = True\n",
    "\n",
    "#specify properties to extract \n",
    "prop_list = ['label', \n",
    "            'area', 'centroid', \n",
    "            'axis_major_length', 'axis_minor_length']\n",
    "\n",
    "#specify processing settings\n",
    "settings = {\n",
    "    #specify the order of the strains in the Ilastik layers\n",
    "    'idx_SA1'   : 0, #SA1 is GFP\n",
    "    'idx_SA2'   : 1, #SA2 is RFP\n",
    "    'idx_BG'    : 2,\n",
    "    'idx_PA'    : 3,\n",
    "    #specify the segementation processing parameters for pseudomonas\n",
    "    'sigma'             : 1, # sigma for gaussian filter\n",
    "    'threshold_PA'      : 0.5, # threshold for segmentation\n",
    "    'closing_radius_PA' : 5, # radius for closing operation\n",
    "    'min_cell_area_PA'  : 20, # minimum area for a cell to be considered\n",
    "    'max_hole_area_PA'  : 100, # maximum area for a hole to be filled\n",
    "    #specify the segementation processing parameters for staph\n",
    "    'sigma'             : 1, # sigma for gaussian filter\n",
    "    'threshold_SA'      : 0.5, # threshold for segmentation\n",
    "    'closing_radius_SA' : 5, # radius for closing operation\n",
    "    'min_cell_area_SA'  : 20, # minimum area for a cell to be considered\n",
    "    'max_hole_area_SA'  : 100, # maximum area for a hole to be filled    \n",
    "    #store path metadata\n",
    "    'path_reg_im'       : path_reg_im,\n",
    "    'path_seg_im'       : path_seg_im,\n",
    "    'path_data_files'    : path_data_files,\n",
    "    'exp_name'          : exp_name\n",
    "}\n",
    "\n",
    "\n",
    "#load metadata and add to settings\n",
    "metadata_path = settings['path_data_files'] / f'agarpad_{exp_name}.csv'\n",
    "pos_metadata = pd.read_csv(metadata_path, index_col=0)\n",
    "settings['pos_metadata'] = pos_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop positions\n",
    "First make sure that all positions are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230411_reg_p000-images_Probabilities.h5\n",
      "20230411_reg_p004-images_Probabilities.h5\n",
      "20230411_reg_p008-images_Probabilities.h5\n",
      "20230411_reg_p015-images_Probabilities.h5\n",
      "20230411_reg_p016-images_Probabilities.h5\n",
      "20230411_reg_p020-images_Probabilities.h5\n"
     ]
    }
   ],
   "source": [
    "pos_list = [f.name for f in sorted(path_seg_im.glob('*_Probabilities.h5'))]\n",
    "for pos in pos_list: print(pos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we loop positions, this will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []\n",
    "csv_dir_pos = settings['path_data_files'] / settings['exp_name']\n",
    "csv_dir_pos.mkdir(exist_ok=True)\n",
    "\n",
    "for pos in pos_list:\n",
    "    try:\n",
    "        #get psotion number\n",
    "        file_name = pos.split('-images')[0]\n",
    "        pos_idx = int(file_name.split('_p')[-1])\n",
    "        \n",
    "        print(f\"Processing position {pos_idx}\")\n",
    "        \n",
    "        #construct file names\n",
    "        file_name_im = f\"{exp_name}_reg_p{pos_idx:03d}.h5\"\n",
    "        file_name_seg = f\"{exp_name}_reg_p{pos_idx:03d}-images_Probabilities.h5\"\n",
    "\n",
    "        #load registered images\n",
    "        reg_im_file = h5py.File(settings['path_reg_im']/file_name_im, 'r') #open \n",
    "        chunk_size = (1, *reg_im_file['images'].shape[-3:])\n",
    "        reg_im = da.from_array(reg_im_file['images'], chunks=chunk_size)\n",
    "\n",
    "        #load segmented images\n",
    "        seg_im_file = h5py.File(settings['path_seg_im']/file_name_seg, 'r') #open \n",
    "        chunk_size = (1, 1,*reg_im_file['images'].shape[-2:])\n",
    "        seg_prob = da.from_array(seg_im_file['exported_data'], chunks=chunk_size)\n",
    "\n",
    "        #crop to max frame\n",
    "        pdata = settings['pos_metadata']\n",
    "        max_frm = int(pdata.loc[f\"pos{pos_idx:03d}\",\"max_frame\"]) if f\"pos{pos_idx:03d}\" in pdata.index else reg_im.shape[0]\n",
    "        reg_im = reg_im[:max_frm]       \n",
    "        seg_prob = seg_prob[:max_frm]       \n",
    "\n",
    "        condition = pdata.loc[f\"pos{pos_idx:03d}\",\"condition\"] if f\"pos{pos_idx:03d}\" in pdata.index else ''\n",
    "        \n",
    "        #convert to labels\n",
    "        SA1_labels = pc.process_seg(seg_prob[:,settings['idx_SA1'],:,:], \n",
    "                                    sigma = settings['sigma'],\n",
    "                                    threshold = settings['threshold_SA'],\n",
    "                                    closing_radius = settings['closing_radius_SA'],\n",
    "                                    min_cell_area = settings['min_cell_area_SA'],\n",
    "                                    max_hole_area = settings['max_hole_area_SA'])\n",
    "                                    \n",
    "        SA2_labels = pc.process_seg(seg_prob[:,settings['idx_SA2'],:,:], \n",
    "                                sigma = settings['sigma'],\n",
    "                                threshold = settings['threshold_SA'],\n",
    "                                closing_radius = settings['closing_radius_SA'],\n",
    "                                min_cell_area = settings['min_cell_area_SA'],\n",
    "                                max_hole_area = settings['max_hole_area_SA'])                       \n",
    "\n",
    "        PA_labels = pc.process_seg(seg_prob[:,settings['idx_PA'],:,:], \n",
    "                                sigma = settings['sigma'],\n",
    "                                threshold = settings['threshold_PA'],\n",
    "                                closing_radius = settings['closing_radius_PA'],\n",
    "                                min_cell_area = settings['min_cell_area_PA'],\n",
    "                                max_hole_area = settings['max_hole_area_PA'])      \n",
    "        \n",
    "        #track colonies and extract properties\n",
    "        df_SA1 = pc.track_extract_prop(SA1_labels, prop_list, \n",
    "                                 metadata = {'pos': pos_idx, 'strain':'SA1','condition':condition})\n",
    "        \n",
    "        df_SA2 = pc.track_extract_prop(SA2_labels, prop_list, \n",
    "                                 metadata = {'pos': pos_idx, 'strain':'SA2','condition':condition})\n",
    "        \n",
    "        df_PA = pc.track_extract_prop(PA_labels, prop_list, \n",
    "                                 metadata = {'pos': pos_idx, 'strain':'PA','condition':condition})\n",
    "        \n",
    "        #combine dataframes\n",
    "        df = pd.concat([df_SA1, df_SA2, df_PA]).reset_index(drop=True)\n",
    "        \n",
    "        #add spatial properties\n",
    "        df = pc.add_centrod_distance(df)\n",
    "        if calc_edge_dist:\n",
    "            df = pc.add_edge2edge_distance(df,PA_labels,SA1_labels,SA2_labels)\n",
    "        \n",
    "        expname = settings[\"exp_name\"]\n",
    "        csv_name = csv_dir_pos / f\"{expname}_pos{pos_idx:03d}.csv\"\n",
    "        df.to_csv(csv_name)\n",
    "        df_all.append(df)\n",
    "        \n",
    "    except:\n",
    "         print(\"Error processing position {}\".format(pos_idx))  \n",
    "        \n",
    "df_combined = pd.concat(df_all).reset_index(drop=True)  \n",
    "csv_name = settings['path_data_files'] / f\"{expname}_all_data.csv\"\n",
    "df_combined.to_csv(csv_name)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "i2i_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6538b57b9d95695cc8c88818812a736980da96b6d92e389fbfaae31437292d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
