{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process segmentation made with Ilastik"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the identical steps as in notebook 3, but in a more streamlined way, allowing for batch processing without visual inspection.\n",
    "\n",
    "The processing functions have been moved to the process_colonies.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#main data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "\n",
    "#path handling\n",
    "import pathlib\n",
    "import h5py\n",
    "\n",
    "#dask cash\n",
    "from dask.cache import Cache\n",
    "cache = Cache(4e9)  # Leverage 4 gigabytes of memory\n",
    "cache.register()    # Turn cache on globally\n",
    "\n",
    "import process_colonies as pc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to registered file\n",
    "path_reg_im = pathlib.Path(\"/Users/simonvanvliet/TempData\")\n",
    "\n",
    "#set path to Ilastik output file\n",
    "path_seg_im = pathlib.Path(\"/Users/simonvanvliet/TempData\")\n",
    "\n",
    "#set path to temporary store label images (use local machine folder for speed)\n",
    "temp_data_path = pathlib.Path.home() / 'TempData'\n",
    "temp_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "#set path to output csv files\n",
    "path_data_files = pathlib.Path('/Users/simonvanvliet/TempData/DataFiles/') \n",
    "path_data_files.mkdir(exist_ok=True)\n",
    "\n",
    "#set filenames\n",
    "exp_name_list = [\"20230411\",\"20230427\"]\n",
    "\n",
    "#specify properties to extract \n",
    "prop_list = ['label', \n",
    "            'area', 'centroid', \n",
    "            'axis_major_length', 'axis_minor_length']\n",
    "\n",
    "#specify processing settings\n",
    "settings = {\n",
    "    'calc_edge_dist'    : True, #set to true to calculate distance between colony edges, more accurate that center to center distance, but very slow\n",
    "    'prop_list'         : prop_list,\n",
    "    #specify the order of the strains in the Ilastik layers\n",
    "    #specify the order of the strains in the Ilastik layers\n",
    "    'idx_SA1'   : 1, #SA1 is GFP\n",
    "    'idx_SA2'   : 0, #SA2 is RFP\n",
    "    'idx_BG'    : 2,\n",
    "    'idx_PA'    : 3,\n",
    "    #specify the segementation processing parameters for pseudomonas\n",
    "    'sigma'             : 1, # sigma for gaussian filter\n",
    "    'threshold_PA'      : 0.5, # threshold for segmentation\n",
    "    'closing_radius_PA' : 5, # radius for closing operation\n",
    "    'min_cell_area_PA'  : 50, # minimum area for a cell to be considered\n",
    "    'max_hole_area_PA'  : 5000, # maximum area for a hole to be filled\n",
    "    #specify the segementation processing parameters for staph\n",
    "    'sigma'             : 2, # sigma for gaussian filter\n",
    "    'threshold_SA'      : 0.5, # threshold for segmentation\n",
    "    'closing_radius_SA' : 5, # radius for closing operation\n",
    "    'min_cell_area_SA'  : 50, # minimum area for a cell to be considered\n",
    "    'max_hole_area_SA'  : 1000, # maximum area for a hole to be filled    \n",
    "    #store path metadata\n",
    "    'temp_path'         : temp_data_path,\n",
    "    'path_seg_im_root'  : path_seg_im,\n",
    "    'path_data_files'    : path_data_files,\n",
    "    'exp_name_list'         : exp_name_list\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop experiments and positions\n",
    "First make sure that all positions are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230411_reg_p000_Probabilities.h5\n",
      "20230411_reg_p001_Probabilities.h5\n",
      "20230411_reg_p002_Probabilities.h5\n",
      "20230411_reg_p003_Probabilities.h5\n",
      "20230411_reg_p004_Probabilities.h5\n",
      "20230411_reg_p005_Probabilities.h5\n",
      "20230411_reg_p006_Probabilities.h5\n",
      "20230411_reg_p007_Probabilities.h5\n",
      "20230411_reg_p008_Probabilities.h5\n",
      "20230411_reg_p009_Probabilities.h5\n",
      "20230411_reg_p010_Probabilities.h5\n",
      "20230411_reg_p011_Probabilities.h5\n",
      "20230411_reg_p012_Probabilities.h5\n",
      "20230411_reg_p013_Probabilities.h5\n",
      "20230411_reg_p014_Probabilities.h5\n",
      "20230411_reg_p015_Probabilities.h5\n",
      "20230411_reg_p016_Probabilities.h5\n",
      "20230411_reg_p017_Probabilities.h5\n",
      "20230411_reg_p018_Probabilities.h5\n",
      "20230411_reg_p019_Probabilities.h5\n",
      "20230411_reg_p020_Probabilities.h5\n",
      "20230411_reg_p021_Probabilities.h5\n",
      "20230411_reg_p022_Probabilities.h5\n",
      "20230411_reg_p023_Probabilities.h5\n",
      "20230427_reg_p000_Probabilities.h5\n",
      "20230427_reg_p001_Probabilities.h5\n",
      "20230427_reg_p002_Probabilities.h5\n",
      "20230427_reg_p003_Probabilities.h5\n",
      "20230427_reg_p004_Probabilities.h5\n",
      "20230427_reg_p005_Probabilities.h5\n",
      "20230427_reg_p006_Probabilities.h5\n",
      "20230427_reg_p007_Probabilities.h5\n",
      "20230427_reg_p008_Probabilities.h5\n",
      "20230427_reg_p009_Probabilities.h5\n",
      "20230427_reg_p010_Probabilities.h5\n",
      "20230427_reg_p011_Probabilities.h5\n",
      "20230427_reg_p012_Probabilities.h5\n",
      "20230427_reg_p013_Probabilities.h5\n",
      "20230427_reg_p014_Probabilities.h5\n",
      "20230427_reg_p015_Probabilities.h5\n",
      "20230427_reg_p016_Probabilities.h5\n",
      "20230427_reg_p017_Probabilities.h5\n",
      "20230427_reg_p018_Probabilities.h5\n",
      "20230427_reg_p019_Probabilities.h5\n",
      "20230427_reg_p020_Probabilities.h5\n",
      "20230427_reg_p021_Probabilities.h5\n",
      "20230427_reg_p022_Probabilities.h5\n",
      "20230427_reg_p023_Probabilities.h5\n",
      "20230504_reg_p000_Probabilities.h5\n",
      "20230504_reg_p001_Probabilities.h5\n",
      "20230504_reg_p002_Probabilities.h5\n",
      "20230504_reg_p003_Probabilities.h5\n",
      "20230504_reg_p004_Probabilities.h5\n",
      "20230504_reg_p005_Probabilities.h5\n",
      "20230504_reg_p006_Probabilities.h5\n",
      "20230504_reg_p007_Probabilities.h5\n",
      "20230504_reg_p008_Probabilities.h5\n",
      "20230504_reg_p009_Probabilities.h5\n",
      "20230504_reg_p010_Probabilities.h5\n",
      "20230504_reg_p011_Probabilities.h5\n",
      "20230504_reg_p012_Probabilities.h5\n",
      "20230504_reg_p013_Probabilities.h5\n",
      "20230504_reg_p014_Probabilities.h5\n",
      "20230504_reg_p015_Probabilities.h5\n",
      "20230504_reg_p016_Probabilities.h5\n",
      "20230504_reg_p017_Probabilities.h5\n",
      "20230504_reg_p018_Probabilities.h5\n",
      "20230504_reg_p019_Probabilities.h5\n",
      "20230504_reg_p020_Probabilities.h5\n",
      "20230504_reg_p021_Probabilities.h5\n",
      "20230504_reg_p022_Probabilities.h5\n",
      "20230504_reg_p023_Probabilities.h5\n"
     ]
    }
   ],
   "source": [
    "for exp_name in exp_name_list:\n",
    "    seg_path = settings['path_seg_im_root'] / f'{exp_name}-agar-pad-processed' \n",
    "    pos_list = [f.name for f in sorted(seg_path.glob('*_Probabilities.h5'))]\n",
    "    for pos in pos_list: print(pos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we loop positions, this will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing position nr 0 name 20230504_reg_p000\n",
      "   Processing position nr 1 name 20230504_reg_p001\n",
      "   Processing position nr 2 name 20230504_reg_p002\n",
      "   Processing position nr 3 name 20230504_reg_p003\n",
      "   Processing position nr 4 name 20230504_reg_p004\n",
      "   Processing position nr 5 name 20230504_reg_p005\n",
      "   Processing position nr 6 name 20230504_reg_p006\n",
      "   Processing position nr 7 name 20230504_reg_p007\n",
      "   Processing position nr 8 name 20230504_reg_p008\n",
      "   Processing position nr 9 name 20230504_reg_p009\n",
      "   Processing position nr 10 name 20230504_reg_p010\n",
      "   Processing position nr 11 name 20230504_reg_p011\n",
      "   Processing position nr 12 name 20230504_reg_p012\n",
      "   Processing position nr 13 name 20230504_reg_p013\n",
      "   Processing position nr 14 name 20230504_reg_p014\n",
      "   Processing position nr 15 name 20230504_reg_p015\n",
      "   Processing position nr 16 name 20230504_reg_p016\n",
      "   Processing position nr 17 name 20230504_reg_p017\n",
      "   Processing position nr 18 name 20230504_reg_p018\n",
      "   Processing position nr 19 name 20230504_reg_p019\n",
      "   Processing position nr 20 name 20230504_reg_p020\n",
      "   Processing position nr 21 name 20230504_reg_p021\n",
      "   Processing position nr 22 name 20230504_reg_p022\n",
      "   Processing position nr 23 name 20230504_reg_p023\n"
     ]
    }
   ],
   "source": [
    "for exp_name in exp_name_list:   \n",
    "    #load metadata and add to settings\n",
    "    metadata_path = settings['path_data_files'] / f'agarpad_{exp_name}.csv'\n",
    "    pos_metadata = pd.read_csv(metadata_path, index_col=0)\n",
    "    \n",
    "    settings['pos_metadata'] = pos_metadata\n",
    "    settings['exp_name'] = exp_name\n",
    "    settings['path_seg_im'] = settings['path_seg_im_root'] / f'{exp_name}-agar-pad-processed' \n",
    "\n",
    "    csv_dir_pos = settings['path_data_files'] / exp_name\n",
    "    csv_dir_pos.mkdir(exist_ok=True)\n",
    "    \n",
    "    #get positions\n",
    "    pos_list = [f.name for f in sorted(settings['path_seg_im'].glob('*_Probabilities.h5'))]\n",
    "    \n",
    "    #segment track and process all positions\n",
    "    for pos in pos_list:\n",
    "        #check if csv file already exists and skip if already processed\n",
    "        \n",
    "        file_name = pos.split('_Prob')[0]\n",
    "        pos_idx = int(file_name.split('_p')[-1])\n",
    "    \n",
    "        csv_dir_pos = settings['path_data_files'] / settings['exp_name']\n",
    "        csv_name = csv_dir_pos / f\"{settings['exp_name']}_pos{pos_idx:03d}.csv\"\n",
    "                \n",
    "        if not csv_name.exists():\n",
    "            print(f\"   Processing position nr {pos_idx} name {file_name}\")\n",
    "            #try:\n",
    "                #segment colony and store label image\n",
    "            df = pc.process_pos(pos_idx, settings, store_2_disk=True, clean_disk=True, max_frame_e2e=20, ignore_edge_e2e=300)\n",
    "            # except:\n",
    "            #     print(\"X-> Error processing position {}\".format(pos))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []\n",
    "for exp_name in exp_name_list:\n",
    "\n",
    "    csv_dir_pos = settings['path_data_files'] / exp_name      \n",
    "    df_exp = [pd.read_csv(pos, index_col=0) for pos in sorted(csv_dir_pos.glob('*_pos*.csv'))]\n",
    "    df_all.append(pd.concat(df_exp).reset_index(drop=True))\n",
    "    \n",
    "df_combined = pd.concat(df_all).reset_index(drop=True)  \n",
    "csv_name = settings['path_data_files'] / \"all_data.csv\"\n",
    "df_combined.to_csv(csv_name)        "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "i2i_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6538b57b9d95695cc8c88818812a736980da96b6d92e389fbfaae31437292d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
