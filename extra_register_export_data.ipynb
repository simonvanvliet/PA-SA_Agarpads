{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and export agar pad movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#next two lines make sure that Matplotlib plots are shown properly in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#next line is required for Napari\n",
    "%gui qt\n",
    "\n",
    "#main data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#image processing packages\n",
    "from scipy import ndimage as ndi\n",
    "import skimage.segmentation as segmentation \n",
    "import skimage.filters as filters\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage import morphology\n",
    "\n",
    "#data plotting packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#set default figure size\n",
    "matplotlib.rc(\"figure\", figsize=(10,5))\n",
    "import seaborn as sns\n",
    "\n",
    "#image viewer\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "#out of memory computation\n",
    "from dask_image.imread import imread\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "#path handling\n",
    "import pathlib\n",
    "\n",
    "#file handling\n",
    "import h5py\n",
    "\n",
    "#Instead of dask_image.imread.imread() you can also use tifffile.imread() to directly read images into memory\n",
    "#import tifffile\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from dask.cache import Cache\n",
    "cache = Cache(2e9)  # Leverage two gigabytes of memory\n",
    "cache.register()    # Turn cache on globally\n",
    "\n",
    "import javabridge as jb\n",
    "import bioformats\n",
    "\n",
    "import nd2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempted file (/Volumes/Giulia/test.ND2) load with reader: aicsimageio.readers.nd2_reader.ND2Reader failed with error: [Errno 13] Permission denied\n"
     ]
    },
    {
     "ename": "UnsupportedFileFormatError",
     "evalue": "AICSImage does not support the image: '/Volumes/Giulia/test.ND2'. File extension suggests format: 'nd2'. Install extra format dependency with: `pip install aicsimageio[nd2]`. See all known format extensions and their extra install name with `aicsimageio.formats.FORMAT_IMPLEMENTATIONS`. If the extra dependency is already installed this error may have raised because the file is corrupt or similar issue. For potentially more information and to help debug, try loading the file directly with the desired file format reader instead of with the AICSImage object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedFileFormatError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maicsimageio\u001b[39;00m \u001b[39mimport\u001b[39;00m AICSImage\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Get an AICSImage object\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m AICSImage(path)  \u001b[39m# selects the first scene found\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m img\u001b[39m.\u001b[39mdask_data  \u001b[39m# returns 5D TCZYX dask array\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m img\u001b[39m.\u001b[39mdims  \u001b[39m# returns a Dimensions object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/miniconda3/envs/i2i_env/lib/python3.9/site-packages/aicsimageio/aics_image.py:264\u001b[0m, in \u001b[0;36mAICSImage.__init__\u001b[0;34m(self, image, reader, reconstruct_mosaic, fs_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    256\u001b[0m     image: types\u001b[39m.\u001b[39mImageLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    261\u001b[0m ):\n\u001b[1;32m    262\u001b[0m     \u001b[39mif\u001b[39;00m reader \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         \u001b[39m# Determine reader class and create dask delayed array\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m         ReaderClass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetermine_reader(image, fs_kwargs\u001b[39m=\u001b[39;49mfs_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    265\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m         \u001b[39m# Init reader\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         ReaderClass \u001b[39m=\u001b[39m reader\n",
      "File \u001b[0;32m~/miniconda/miniconda3/envs/i2i_env/lib/python3.9/site-packages/aicsimageio/aics_image.py:218\u001b[0m, in \u001b[0;36mAICSImage.determine_reader\u001b[0;34m(image, fs_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m readers[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m READER_TO_INSTALL:\n\u001b[1;32m    217\u001b[0m     installer \u001b[39m=\u001b[39m READER_TO_INSTALL[readers[\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnsupportedFileFormatError(\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAICSImage\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         path,\n\u001b[1;32m    221\u001b[0m         msg_extra\u001b[39m=\u001b[39m(\n\u001b[1;32m    222\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile extension suggests format: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mformat_ext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInstall extra format dependency with: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`pip install \u001b[39m\u001b[39m{\u001b[39;00minstaller\u001b[39m}\u001b[39;00m\u001b[39m`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSee all known format extensions and their \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mextra install name with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`aicsimageio.formats.FORMAT_IMPLEMENTATIONS`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf the extra dependency is already installed this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39merror may have raised because the file is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorrupt or similar issue. For potentially more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minformation and to help debug, try loading the file \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdirectly with the desired file format reader \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of with the AICSImage object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m         ),\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnsupportedFileFormatError(\n\u001b[1;32m    238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAICSImage\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m         path,\n\u001b[1;32m    240\u001b[0m     )\n",
      "\u001b[0;31mUnsupportedFileFormatError\u001b[0m: AICSImage does not support the image: '/Volumes/Giulia/test.ND2'. File extension suggests format: 'nd2'. Install extra format dependency with: `pip install aicsimageio[nd2]`. See all known format extensions and their extra install name with `aicsimageio.formats.FORMAT_IMPLEMENTATIONS`. If the extra dependency is already installed this error may have raised because the file is corrupt or similar issue. For potentially more information and to help debug, try loading the file directly with the desired file format reader instead of with the AICSImage object."
     ]
    }
   ],
   "source": [
    "\n",
    "path = r\"/Volumes/Giulia/test.ND2\"\n",
    "\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "# Get an AICSImage object\n",
    "img = AICSImage(path)  # selects the first scene found\n",
    "img.dask_data  # returns 5D TCZYX dask array\n",
    "img.dims  # returns a Dimensions object\n",
    "img.dims.order  # returns string \"TCZYX\"\n",
    "img.dims.X  # returns size of X dimension\n",
    "img.shape  # returns tuple of dimension sizes in TCZYX order\n",
    "\n",
    "img.get_xarray_dask_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/miniconda3/envs/i2i_env/lib/python3.9/site-packages/nd2/_util.py:68\u001b[0m, in \u001b[0;36mget_reader\u001b[0;34m(path, validate_frames, search_window, read_using_sdk)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_sdk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlatest\u001b[39;00m \u001b[39mimport\u001b[39;00m ND2Reader\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m ND2Reader(\n\u001b[1;32m     69\u001b[0m         path,\n\u001b[1;32m     70\u001b[0m         validate_frames\u001b[39m=\u001b[39;49mvalidate_frames,\n\u001b[1;32m     71\u001b[0m         search_window\u001b[39m=\u001b[39;49msearch_window,\n\u001b[1;32m     72\u001b[0m         read_using_sdk\u001b[39m=\u001b[39;49mread_using_sdk,\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m \u001b[39melif\u001b[39;00m magic_num \u001b[39m==\u001b[39m OLD_HEADER_MAGIC:\n",
      "File \u001b[0;32msrc/nd2/_sdk/latest.pyx:61\u001b[0m, in \u001b[0;36mnd2._sdk.latest.ND2Reader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Volumes/Giulia/test.ND2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m f \u001b[39m=\u001b[39m nd2\u001b[39m.\u001b[39;49mND2File(path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m raw_data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mto_dask()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonvanvliet/switchdrive/Biozentrum/Code/PA-SA_Agarpads/extra_register_export_data.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda/miniconda3/envs/i2i_env/lib/python3.9/site-packages/nd2/nd2file.py:98\u001b[0m, in \u001b[0;36mND2File.__init__\u001b[0;34m(self, path, validate_frames, search_window, read_using_sdk)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m\"\"\"Open an nd2 file.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path)\n\u001b[0;32m---> 98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rdr \u001b[39m=\u001b[39m get_reader(\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path,\n\u001b[1;32m    100\u001b[0m     validate_frames\u001b[39m=\u001b[39;49mvalidate_frames,\n\u001b[1;32m    101\u001b[0m     search_window\u001b[39m=\u001b[39;49msearch_window,\n\u001b[1;32m    102\u001b[0m     read_using_sdk\u001b[39m=\u001b[39;49mread_using_sdk,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLegacy\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rdr)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/miniconda3/envs/i2i_env/lib/python3.9/site-packages/nd2/_util.py:78\u001b[0m, in \u001b[0;36mget_reader\u001b[0;34m(path, validate_frames, search_window, read_using_sdk)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_legacy\u001b[39;00m \u001b[39mimport\u001b[39;00m LegacyND2Reader\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m LegacyND2Reader(path)\n\u001b[0;32m---> 78\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m     79\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not recognized as ND2.  First 4 bytes: \u001b[39m\u001b[39m{\u001b[39;00mmagic_num\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m )\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/Giulia/test.ND2\"\n",
    "f = nd2.ND2File(path)\n",
    "raw_data = f.to_dask()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_logger():\n",
    "    \"\"\"This is so that Javabridge doesn't spill out a lot of DEBUG messages\n",
    "    during runtime.\n",
    "    From CellProfiler/python-bioformats.\n",
    "    \"\"\"\n",
    "    rootLoggerName = jb.get_static_field(\"org/slf4j/Logger\",\n",
    "                                         \"ROOT_LOGGER_NAME\",\n",
    "                                         \"Ljava/lang/String;\")\n",
    "\n",
    "    rootLogger = jb.static_call(\"org/slf4j/LoggerFactory\",\n",
    "                                \"getLogger\",\n",
    "                                \"(Ljava/lang/String;)Lorg/slf4j/Logger;\",\n",
    "                                rootLoggerName)\n",
    "\n",
    "    logLevel = jb.get_static_field(\"ch/qos/logback/classic/Level\",\n",
    "                                   \"WARN\",\n",
    "                                   \"Lch/qos/logback/classic/Level;\")\n",
    "\n",
    "    jb.call(rootLogger,\n",
    "            \"setLevel\",\n",
    "            \"(Lch/qos/logback/classic/Level;)V\",\n",
    "            logLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb.start_vm(class_path=bioformats.JARS)\n",
    "logger = _init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to ND2 file\n",
    "path = pathlib.Path('/Volumes/RG van Vliet/Scientific Data/Giulia/Collaborations/Ashley/2023-01-20-agar-pad/2023-01-20-agar-pad.nd2')\n",
    "\n",
    "#set folder where to store output files\n",
    "process_dir = pathlib.Path('/Volumes/RG van Vliet/Scientific Data/Giulia/Collaborations/Ashley/2023-01-20-agar-pad-processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(path, pathlib.PurePath)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.image(0).Pixels.channel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = bioformats.ImageReader(str(path.resolve()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18062, 18418, 18383, ..., 17893, 17934, 17610],\n",
       "       [17743, 18404, 18488, ..., 17343, 18138, 17576],\n",
       "       [18088, 18587, 18157, ..., 17789, 18027, 17646],\n",
       "       ...,\n",
       "       [16764, 16382, 16892, ..., 17038, 16783, 16653],\n",
       "       [16367, 16923, 16647, ..., 16661, 16760, 17047],\n",
       "       [16707, 16460, 16443, ..., 16754, 16611, 16774]], dtype=uint16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.read(series=0, c=0, t=0, rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = dask.delayed(im.read(series=0,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 36.49 GiB </td>\n",
       "                        <td> 36.49 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (30, 52, 3, 2044, 2048) </td>\n",
       "                        <td> (30, 52, 3, 2044, 2048) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint16 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"384\" height=\"184\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"30\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"27\" x2=\"30\" y2=\"27\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"27\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"27\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 30.402120449703666,0.0 30.402120449703666,27.33282571158194 0.0,27.33282571158194\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"15.201060\" y=\"47.332826\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >52</text>\n",
       "  <text x=\"50.402120\" y=\"13.666413\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,50.402120,13.666413)\">30</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"114\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"100\" y1=\"119\" x2=\"114\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"100\" y2=\"119\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"114\" y1=\"14\" x2=\"114\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"100.0,0.0 114.9485979497544,14.948597949754403 114.9485979497544,134.7142229497544 100.0,119.765625\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"220\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"114\" y1=\"14\" x2=\"234\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"114\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"220\" y1=\"0\" x2=\"234\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"100.0,0.0 220.0,0.0 234.9485979497544,14.948597949754403 114.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"114\" y1=\"14\" x2=\"234\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"114\" y1=\"134\" x2=\"234\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"114\" y1=\"14\" x2=\"114\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"234\" y1=\"14\" x2=\"234\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"114.9485979497544,14.948597949754403 234.9485979497544,14.948597949754403 234.9485979497544,134.7142229497544 114.9485979497544,134.7142229497544\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"174.948598\" y=\"154.714223\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2048</text>\n",
       "  <text x=\"254.948598\" y=\"74.831410\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,254.948598,74.831410)\">2044</text>\n",
       "  <text x=\"97.474299\" y=\"147.239924\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,97.474299,147.239924)\">3</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-value, shape=(30, 52, 3, 2044, 2048), dtype=uint16, chunksize=(30, 52, 3, 2044, 2048), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.from_delayed(value, (30, 52, 3, 2044, 2048), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys =  ['exported_data']\n"
     ]
    }
   ],
   "source": [
    "seg_path = root / segment_name #path to Ilastik output\n",
    "seg_data = h5py.File(seg_path, 'r') #open \n",
    "print('keys = ', list(seg_data.keys()))\n",
    "\n",
    "#we again use Dask to load the data out of memory\n",
    "#technical comment: we set chunk size to be equal to the size of single frame. \n",
    "chuck_size = (1, *im_stack.shape[-2:]) if n_channel==1 else (1, n_channel, *im_stack.shape[-2:])\n",
    "seg_cell = da.from_array(seg_data['exported_data'], chunks=chuck_size)\n",
    "\n",
    "#we get a segmentation probability for both labels (cells and BG) but only need the one for the cells, so we extract the correct dimension:\n",
    "seg_cell = seg_cell[:,fg_idx,:,:]\n",
    "\n",
    "#add probability layer to Napari Viewer\n",
    "prop_layer = viewer.add_image(seg_cell, name='probability',colormap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 52 3 2044 2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.nd2file at 0x17ba637c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd2file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nd2file:  \n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        if isinstance(path, pathlib.PurePath):\n",
    "            path = str(path.resolve()) \n",
    "                  \n",
    "        self.path = path\n",
    "        self.imhandle = bioformats.ImageReader(path)\n",
    "\n",
    "        md = bioformats.OMEXML(bioformats.get_omexml_metadata(path))  \n",
    "        self.p = md.get_image_count()\n",
    "        self.t = md.image(0).Pixels.SizeT\n",
    "        self.c = md.image(0).Pixels.channel_count\n",
    "        self.x = md.image(0).Pixels.SizeX\n",
    "        self.y = md.image(0).Pixels.SizeY\n",
    "        \n",
    "        print(self.p,self.t,self.c,self.y,self.x)\n",
    "        \n",
    "#     def _load_im(self):  \n",
    "        \n",
    "#         chuck_size = (1, *im_stack.shape[-2:]) if n_channel==1 else (1, n_channel, *im_stack.shape[-2:])\n",
    "# seg_cell = da.from_array(seg_data['exported_data'], chunks=chuck_size)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         output =   \n",
    "#         # Load images:\n",
    "#         for p, pos in enumerate(self.p):\n",
    "#             for c, cha in enumerate(self.c):\n",
    "#                 for f, fra in enumerate(self.t):\n",
    "#                     # Read frame:\n",
    "#                     frame = self.filehandle.read(\n",
    "#                             series=pos, c=cha, t=fra, rescale=False\n",
    "#                         )\n",
    "                \n",
    "#                     # Add to output array:\n",
    "#                     output[p, f, c, :, :] = frame\n",
    "                    \n",
    "#         return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "# Get an AICSImage object\n",
    "img = AICSImage(path_str)  # selects the first scene found\n",
    "img.dask_data  # returns 5D TCZYX dask array\n",
    "img.dims  # returns a Dimensions object\n",
    "img.dims.order  # returns string \"TCZYX\"\n",
    "img.dims.X  # returns size of X dimension\n",
    "img.shape  # returns tuple of dimension sizes in TCZYX order\n",
    "\n",
    "img.get_xarray_dask_stack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set number of color channels in image\n",
    "n_channel = 3\n",
    "\n",
    "#set the sample interval, in each subfolder we will sample images at this interval (e.g. with sample_int=3 we will sample image 0, 3, 6, etc)\n",
    "#adjust this number to have ~2 images per subfolder\n",
    "sample_int = 3 \n",
    "\n",
    "#we will extract two channels here: phase contrast + fluorescence \n",
    "ch0 = [] # phase contrast channel\n",
    "ch1 = [] # fluorescence channel of constitutive marker\n",
    "\n",
    "for f in folder_names: # loop subfolders\n",
    "    im_names = [i.name for i in sorted((root / f).glob('*.tif*'))]\n",
    "    \n",
    "    for idx, i in enumerate(im_names): #loop images\n",
    "        if idx%sample_int==0:\n",
    "            im_path = root / f / i\n",
    "            im_stack = imread(im_path)\n",
    "            nfr = im_stack.shape[0]/n_channel\n",
    "            \n",
    "            #here we set which frames we sample, adapt to your own images, take frames at start, middle, and end\n",
    "            frames = [0, max(nfr - 31, 0), max(nfr - 21, 0), nfr-11]\n",
    "            \n",
    "            for fr in frames:\n",
    "                ch0_idx = fr*n_channel\n",
    "                ch1_idx = fr*n_channel + 2\n",
    "                ch0.append(np.squeeze(im_stack[ch0_idx,:,:]))\n",
    "                ch1.append(np.squeeze(im_stack[ch1_idx,:,:]))\n",
    "\n",
    "\n",
    "ch0_stack = np.stack(ch0, axis=0)    \n",
    "ch1_stack = np.stack(ch1, axis=0)   \n",
    "mc_stack = np.stack([ch0_stack, ch1_stack], axis=0)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store as hdf5\n",
    "outname = process_dir /  'traning_data_excl_last.hdf5'\n",
    "\n",
    "h5f = h5py.File(outname, 'w')\n",
    "h5f.create_dataset('dataset_1', data=mc_stack)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store as tiff\n",
    "ch0n = process_dir / 'ph_training.tif'\n",
    "ch1n = process_dir / 'gfp_training.tif'\n",
    "\n",
    "tifffile.imwrite(ch0n, ch0_stack)\n",
    "tifffile.imwrite(ch1n, ch1_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class register_pos:\n",
    "    \n",
    "    def __init__(self, pos, ch=0):\n",
    "        self.pos = pos\n",
    "        self.ch = ch\n",
    "        self.transform = da.empty(0)\n",
    "        self.reg_im = da.empty(0)\n",
    "        return None\n",
    "    \n",
    "    def calc(self):\n",
    "        self.transform = self._register_pos_calc().compute()\n",
    "        self.reg_im = self._register_pos_apply()\n",
    "        return reg_im  \n",
    "\n",
    "    @dask.delayed\n",
    "    def _get_shift(self, frm0, frm1):\n",
    "        dxy, _, _ = phase_cross_correlation(np.squeeze(frm0),np.squeeze(frm1))\n",
    "        return dxy\n",
    "\n",
    "    @dask.delayed\n",
    "    def _apply_shift(self, frm, dyx):\n",
    "        return ndi.shift(frm, [0,*dyx], cval=0, order=0)\n",
    "\n",
    "    def _register_pos_calc(self):\n",
    "        shift = da.zeros((self.pos.shape[0],2), chunks=(1, 2))\n",
    "        for t in range(self.pos.shape[0]-1):\n",
    "            dxy = self._get_shift(self.pos[t,self.ch,:,:], self.pos[t+1,self.ch,:,:])\n",
    "            shift[t+1,:] = da.from_delayed(dxy, shape=(1, 2), dtype=np.float64)\n",
    "        return np.cumsum(shift, axis=0)     \n",
    "\n",
    "    def _register_pos_apply(self):\n",
    "        reg_im = da.empty_like(self.pos)\n",
    "        for t in range(self.pos.shape[0]):\n",
    "            im = self._apply_shift(self.pos[t,:,:,:], transform[t,:])\n",
    "            reg_im[t,:,:,:] = da.from_delayed(im, shape=(self.pos.shape[1:]), dtype=np.float64)\n",
    "        return reg_im"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "i2i_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6538b57b9d95695cc8c88818812a736980da96b6d92e389fbfaae31437292d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
